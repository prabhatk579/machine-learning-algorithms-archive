{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLA_II.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit (windows store)"
    },
    "interpreter": {
      "hash": "af39598f9ec1097dfe94f27266726cd57d6470cb4734b038c68eadc467a2f598"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "412lY1YncRkL",
        "outputId": "7cab15b8-626d-4749-9b23-723e2f2b2a9d"
      },
      "source": [
        "# Logistic regeression\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "num_folds = 8\n",
        "kfold = KFold(n_splits=8)\n",
        "model = LogisticRegression()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7760416666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "sRk6pEYHuR1O",
        "outputId": "75074371-8ff4-4eae-cca2-5633b16e3294"
      },
      "source": [
        "dataframe = read_csv(filename, names=names)\n",
        "dataframe"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>test</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     preg  plas  pres  skin  test  mass   pedi  age  class\n",
              "0       6   148    72    35     0  33.6  0.627   50      1\n",
              "1       1    85    66    29     0  26.6  0.351   31      0\n",
              "2       8   183    64     0     0  23.3  0.672   32      1\n",
              "3       1    89    66    23    94  28.1  0.167   21      0\n",
              "4       0   137    40    35   168  43.1  2.288   33      1\n",
              "..    ...   ...   ...   ...   ...   ...    ...  ...    ...\n",
              "763    10   101    76    48   180  32.9  0.171   63      0\n",
              "764     2   122    70    27     0  36.8  0.340   27      0\n",
              "765     5   121    72    23   112  26.2  0.245   30      0\n",
              "766     1   126    60     0     0  30.1  0.349   47      1\n",
              "767     1    93    70    31     0  30.4  0.315   23      0\n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzKwaajRuSLI",
        "outputId": "75b555ee-aad0-4e85-a652-71065d8716ca"
      },
      "source": [
        "array = dataframe.values\n",
        "array"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1YnD_5auR9A",
        "outputId": "5a5fada1-898c-4c2f-b5d7-00f7b345302c"
      },
      "source": [
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKP-NQ_5uRoK",
        "outputId": "9ed59938-8a66-4d3d-bd51-865c3a7bada1"
      },
      "source": [
        "num_folds = 8\n",
        "kfold = KFold(n_splits=8)\n",
        "model = LogisticRegression()\n",
        "print(kfold)\n",
        "print(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KFold(n_splits=8, random_state=None, shuffle=False)\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_rSWGs-c6QA",
        "outputId": "38781a47-a6e8-43a7-cc1d-14a149e6e1b8"
      },
      "source": [
        "# LDA Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "num_folds = 10\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = LinearDiscriminantAnalysis()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.773462064251538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tQjx0cfkFX1",
        "outputId": "e3ed09f6-b27a-42b1-b22d-f3dfb93d0733"
      },
      "source": [
        "# KNN Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "num_folds = 10\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = KNeighborsClassifier()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7265550239234451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buwrpHE3kLDm",
        "outputId": "36af0a3f-6a78-442f-a6e9-0af00894fdb2"
      },
      "source": [
        "# Gaussian Naive Bayes Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = GaussianNB()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7551777170198223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6txjY_cvkW27",
        "outputId": "3ac85cd3-5530-4238-b88f-d91a3203b431"
      },
      "source": [
        "# Classification and Regression Test Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = DecisionTreeClassifier()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6874060150375939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5CDm-YnkhKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0966c2eb-6062-4812-aa14-64e164af413d"
      },
      "source": [
        "# Support Vector Machines Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = SVC()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7604237867395763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTJ7IEfYmIZe",
        "outputId": "9a2e2806-a4dc-4e03-8ac9-a205c4d8eb83"
      },
      "source": [
        "# Linear Regression\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "filename = 'housing.csv'\n",
        "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
        "'B', 'LSTAT', 'MEDV'] # 14\n",
        "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:13]\n",
        "Y = array[:,13]\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = LinearRegression()\n",
        "scoring = 'neg_mean_squared_error'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(results.mean())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-34.70525594452488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YP8W0o_mi2T",
        "outputId": "5a473eb3-66c3-4168-cb6b-33f2e834b43a"
      },
      "source": [
        "# Lasso Regression\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import Lasso\n",
        "filename = 'housing.csv'\n",
        "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
        "'B', 'LSTAT', 'MEDV']\n",
        "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:13]\n",
        "Y = array[:,13]\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = Lasso()\n",
        "scoring = 'neg_mean_squared_error'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(results.mean())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-34.46408458830232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gpjEeDEn7f8",
        "outputId": "c0a423c7-0ffd-4168-f6e7-9de75f15927e"
      },
      "source": [
        "# ElasticNet Regression\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import ElasticNet\n",
        "filename = 'housing.csv'\n",
        "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
        "'B', 'LSTAT', 'MEDV']\n",
        "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:13]\n",
        "Y = array[:,13]\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = ElasticNet()\n",
        "scoring = 'neg_mean_squared_error'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(results.mean())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-31.164573714249762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh_IwfKqn_6R",
        "outputId": "49be1483-d6e6-466c-9c65-eca887c4c378"
      },
      "source": [
        "# KNN Regression\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "filename = 'housing.csv'\n",
        "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
        "'B', 'LSTAT', 'MEDV']\n",
        "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:13]\n",
        "Y = array[:,13]\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = KNeighborsRegressor()\n",
        "scoring = 'neg_mean_squared_error'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(results.mean())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-107.28683898039215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m39macqfoVIz",
        "outputId": "f8f1fde3-d9e1-4cad-f4e7-98fa9abd318b"
      },
      "source": [
        "# Decision Tree Regression\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "filename = 'housing.csv'\n",
        "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
        "'B', 'LSTAT', 'MEDV']\n",
        "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:13]\n",
        "Y = array[:,13]\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = DecisionTreeRegressor()\n",
        "scoring = 'neg_mean_squared_error'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(results.mean())\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-43.8637968627451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHUXhhiOo0Nu",
        "outputId": "2f3a7c8b-9d3d-4738-e273-27b0dd3c5fc1"
      },
      "source": [
        "# Support Veector Machines Regression\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVR\n",
        "filename = 'housing.csv'\n",
        "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
        "'B', 'LSTAT', 'MEDV']\n",
        "dataframe = read_csv(filename, delim_whitespace=True, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:13]\n",
        "Y = array[:,13]\n",
        "num_folds = 10\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = SVR()\n",
        "scoring = 'neg_mean_squared_error'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(results.mean())\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-72.25543311855311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Ww3hc_pPqX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20aa1362-052e-445e-c0e6-25c2627762a0"
      },
      "source": [
        "# Compare Algorithms\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "# load dataset\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "  kfold = KFold(n_splits=8)\n",
        "  cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = pyplot.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "pyplot.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "pyplot.show()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR: 0.776042 (0.046585)\n",
            "LDA: 0.773438 (0.049889)\n",
            "KNN: 0.718750 (0.028048)\n",
            "CART: 0.713542 (0.042313)\n",
            "NB: 0.753906 (0.041319)\n",
            "SVM: 0.760417 (0.039665)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJYS0iVRpkI8",
        "outputId": "058b99b7-c070-4835-e01c-6b25462a3873"
      },
      "source": [
        "# Create a pipeline that standardizes the data then creates a model\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "# load data\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "# create pipeline\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
        "model = Pipeline(estimators)\n",
        "# evaluate pipeline\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.773462064251538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOv8vvtrrMid",
        "outputId": "ec6e95ed-1c78-4a00-e14f-68fc5688b4b0"
      },
      "source": [
        "# Create a pipeline that extracts features from the data then creates a model\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "# load data\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "# create feature union\n",
        "features = []\n",
        "features.append(('pca', PCA(n_components=3)))\n",
        "features.append(('select_best', SelectKBest(k=4)))\n",
        "feature_union = FeatureUnion(features)\n",
        "# create pipeline\n",
        "estimators = []\n",
        "estimators.append(('feature_union', feature_union))\n",
        "estimators.append(('logistic', LogisticRegression()))\n",
        "model = Pipeline(estimators)\n",
        "# evaluate pipeline\n",
        "kfold = KFold(n_splits=8)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7630208333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcNcQCOMrZH8",
        "outputId": "7ba68281-1d8e-4412-bbd4-57be0681643b"
      },
      "source": [
        "# Create a pipeline that extracts features from the data then creates a model\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "# load data\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "# create feature union\n",
        "features = []\n",
        "features.append(('pca', PCA(n_components=3)))\n",
        "features.append(('select_best', SelectKBest(k=4)))\n",
        "feature_union = FeatureUnion(features)\n",
        "# create pipeline\n",
        "estimators = []\n",
        "estimators.append(('feature_union', feature_union))\n",
        "estimators.append(('logistic', LogisticRegression()))\n",
        "model = Pipeline(estimators)\n",
        "# evaluate pipeline\n",
        "kfold = KFold(n_splits=8)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7630208333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9iU-H9psSqU",
        "outputId": "13d7ba28-bc80-4829-812b-03403d378d00"
      },
      "source": [
        "# Bagged Decision Trees for Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "seed = 7\n",
        "kfold = KFold(n_splits=10, random_state=seed)\n",
        "cart = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.770745044429255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYswB3ebs03j",
        "outputId": "94f3e19f-1fdc-4f88-9dad-0f893281659f"
      },
      "source": [
        "# Random Forest Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7656185919343814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMFRgjtCtPyV",
        "outputId": "ac203c05-0906-4b86-a562-dcee3849e3d2"
      },
      "source": [
        "# Extra Trees Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "num_trees = 100\n",
        "max_features = 7\n",
        "kfold = KFold(n_splits=10)\n",
        "model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7577409432672589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBaIDMHTtnzR",
        "outputId": "6d3e7a2a-02eb-4e4e-c6b1-dde96a6358fd"
      },
      "source": [
        "# AdaBoost Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "num_trees = 30\n",
        "seed=7\n",
        "kfold = KFold(n_splits=10)\n",
        "model = AdaBoostClassifier(n_estimators=num_trees)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n",
        "print(model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.760457963089542\n",
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=30, random_state=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH3V-4EcuM1P",
        "outputId": "a71e5d87-d9a2-4e07-b98d-3818945c9025"
      },
      "source": [
        "# Stochastic Gradient Boosting Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "num_trees = 100\n",
        "kfold = KFold(n_splits=10)\n",
        "model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7681989063568012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-ysLfLLt-Tw",
        "outputId": "7aae2aaf-4e88-4b0d-878a-46a922f8892b"
      },
      "source": [
        "# Voting Ensemble for Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "# create the sub models\n",
        "estimators = []\n",
        "model1 = LogisticRegression()\n",
        "estimators.append(('logistic', model1))\n",
        "print(estimators)\n",
        "model2 = DecisionTreeClassifier()\n",
        "estimators.append(('cart', model2))\n",
        "print(estimators)\n",
        "model3 = SVC()\n",
        "estimators.append(('svm', model3))\n",
        "print(estimators)\n",
        "# create the ensemble model\n",
        "ensemble = VotingClassifier(estimators)\n",
        "results = cross_val_score(ensemble, X, Y, cv=kfold)\n",
        "print(ensemble)\n",
        "print(model1)\n",
        "print(model2)\n",
        "print(model3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False))]\n",
            "[('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)), ('cart', DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'))]\n",
            "[('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)), ('cart', DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')), ('svm', SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False))]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "VotingClassifier(estimators=[('logistic',\n",
            "                              LogisticRegression(C=1.0, class_weight=None,\n",
            "                                                 dual=False, fit_intercept=True,\n",
            "                                                 intercept_scaling=1,\n",
            "                                                 l1_ratio=None, max_iter=100,\n",
            "                                                 multi_class='auto',\n",
            "                                                 n_jobs=None, penalty='l2',\n",
            "                                                 random_state=None,\n",
            "                                                 solver='lbfgs', tol=0.0001,\n",
            "                                                 verbose=0, warm_start=False)),\n",
            "                             ('cart',\n",
            "                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
            "                                                     class_weight=None,\n",
            "                                                     criterion...\n",
            "                                                     presort='deprecated',\n",
            "                                                     random_state=None,\n",
            "                                                     splitter='best')),\n",
            "                             ('svm',\n",
            "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
            "                                  class_weight=None, coef0=0.0,\n",
            "                                  decision_function_shape='ovr', degree=3,\n",
            "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
            "                                  probability=False, random_state=None,\n",
            "                                  shrinking=True, tol=0.001, verbose=False))],\n",
            "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
            "                 weights=None)\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLhCWbDPwkah",
        "outputId": "4d70d86c-20b4-4244-c729-9badcc5d1c31"
      },
      "source": [
        "print(results.mean())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7655673274094327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WhBvP7OwwAv",
        "outputId": "c24d94e0-7433-4d15-87cb-6a5546641e23"
      },
      "source": [
        "# Grid Search for Algorithm Tuning\n",
        "import numpy\n",
        "from pandas import read_csv\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "alphas = numpy.array([1,0.1,0.01,0.001,0.0001,0])\n",
        "param_grid = dict(alpha=alphas)\n",
        "model = Ridge()\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid.fit(X, Y)\n",
        "print(grid.best_score_)\n",
        "print(grid.best_estimator_.alpha)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2761084412929244\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7V9AwjwxXoD",
        "outputId": "8f0136a3-0b9e-4eba-f88a-0f7303523ce0"
      },
      "source": [
        "# Randomized for Algorithm Tuning\n",
        "import numpy\n",
        "from pandas import read_csv\n",
        "from scipy.stats import uniform\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "param_grid = {'alpha': uniform()}\n",
        "model = Ridge()\n",
        "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100,\n",
        "random_state=7)\n",
        "rsearch.fit(X, Y)\n",
        "print(rsearch.best_score_)\n",
        "print(rsearch.best_estimator_.alpha)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.27610755734028525\n",
            "0.9779895119966027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM2LruAvxflG",
        "outputId": "c1a73aba-995a-4116-862d-56048894a042"
      },
      "source": [
        "# Save Model Using Pickle\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from pickle import dump\n",
        "from pickle import load\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)\n",
        "# Fit the model on 33%\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "# save the model to disk\n",
        "filename = 'finalized_model.sav'\n",
        "dump(model, open(filename, 'wb'))\n",
        "# some time later...\n",
        "# load the model from disk\n",
        "loaded_model = load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, Y_test)\n",
        "print(result)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7440944881889764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxmeOqmyxvV_",
        "outputId": "f8fef511-b99c-4bef-f5ff-ac8eb7443db4"
      },
      "source": [
        "# Save Model Using joblib\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.externals.joblib import dump\n",
        "from sklearn.externals.joblib import load\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "# Fit the model on 33%\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "# save the model to disk\n",
        "filename = 'finalized_model.sav'\n",
        "dump(model, filename)\n",
        "# some time later...\n",
        "# load the model from disk\n",
        "loaded_model = load(filename)\n",
        "result = loaded_model.score(X_test, Y_test)\n",
        "print(result)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7874015748031497\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
